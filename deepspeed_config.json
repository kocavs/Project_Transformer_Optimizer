{
    "train_batch_size": 32,
    "gradient_accumulation_steps": 1,
    "scheduler": {
      "type": "WarmupLR",
      "params": {
        "warmup_min_lr": 0,
        "warmup_max_lr": 5e-5,
        "warmup_num_steps": 1000
      }
    },
    "optimizer": {
      "type": "AdamW",
      "params": {
        "lr": 5e-5,
        "betas": [
          0.9,
          0.999
        ],
        "eps": 1e-8,
        "weight_decay": 1e-2
      }
    },
    "pipeline": {
      "stages": 2,
      "partition_method": "uniform",
      "placement_strategy": "spread"
    }
  }
  